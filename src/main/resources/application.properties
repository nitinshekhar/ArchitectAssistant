
server.port = 8080
spring.profile.active=dev

llama.base-url=http://localhost:8081
llama.model-path="/Users/nshekhar/Workspace/model/llama.cpp/llama-2-7b-chat.Q4_K_M.gguf"
llama.context-size=4096
llama.temperature=0.7
llama.max-tokens=2048
llama.model-name="llama"

plantuml.output-directory=target/diagrams
plantuml.image-format=PNG

logging.level.com.nitin=DEBUG
logging.level.dev.lanchain4j=DEBUG

